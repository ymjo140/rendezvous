import time
import random
import requests
import re
import numpy as np
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from typing import List, Tuple

# ğŸŒŸ ê¸°ì¡´ ëª¨ë“ˆ ì„í¬íŠ¸
import models
from database import Base, DATABASE_URL
from constants import NAVER_SEARCH_ID, NAVER_SEARCH_SECRET, NAVER_MAP_ID, NAVER_MAP_SECRET

# --- ì„¤ì • ---
SEARCH_API_URL = "https://openapi.naver.com/v1/search/local.json"
GEOCODE_API_URL = "https://naveropenapi.apigw.ntruss.com/map-geocode/v2/geocode"

engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

# ğŸŒŸ [ì‚¬ìš©ì ìš”ì²­] ì „ì²´ í‚¤ì›Œë“œ ì‚¬ì „ (ê·¸ëŒ€ë¡œ ë°˜ì˜)
TARGET_KEYWORDS_DICT = {
    "í•œì‹": ["í•œì‹", "í•œì •ì‹", "ì†¥ë°¥", "ê°ˆë¹„", "ë¶ˆê³ ê¸°", "ë³´ìŒˆ", "í•œìš°"],
    "ì–‘ì‹": ["ì–‘ì‹", "íŒŒìŠ¤íƒ€", "ìŠ¤í…Œì´í¬", "ë¸ŒëŸ°ì¹˜", "ì´íƒˆë¦¬ì•ˆ", "ë‡¨ë¼", "ë¼ìëƒ", "ì•„ë©”ë¦¬ì¹¸", "ì´íƒœë¦¬"],
    "ì¼ì‹": ["ì¼ì‹", "ìŠ¤ì‹œ", "ë¼ë©˜", "ëˆì¹´ì¸ ", "ëˆê¹ŒìŠ¤", "ìš°ë™", "ê°€ì´ì„¸í‚¤", "ì˜¤ë§ˆì¹´ì„¸", "ì´ìì¹´ì•¼", "ì¼ì‹ì½”ìŠ¤", "í›„í† ë§ˆí‚¤"],
    "ì¤‘ì‹": ["ì¤‘ì‹", "ì¤‘êµ­ìš”ë¦¬", "ì§œì¥ë©´", "ì§¬ë½•", "íƒ•ìˆ˜ìœ¡", "ì¤‘ì‹ë‹¹", "ì½”ìŠ¤ìš”ë¦¬", "ë”¤ì„¬", "í› ê¶ˆ"],
    "ì‹ì‚¬ë¯¸íŒ…": ["ë£¸ì‹ë‹¹", "í•œì •ì‹", "ì¼ì‹ì½”ìŠ¤", "í˜¸í…”ë‹¤ì´ë‹", "ì¡°ìš©í•œì‹ë‹¹", "ì ‘ëŒ€ì¥ì†Œ"],
    "ìˆ ": ["ì´ìì¹´ì•¼", "ì™€ì¸ë°”", "ìœ„ìŠ¤í‚¤ë°”", "í”„ë¼ì´ë¹—ë£¸"],
    "ì»¤í”¼ì±—": ["í˜¸í…”ë¼ìš´ì§€", "ì¡°ìš©í•œì¹´í˜", "ë¹„ì¦ˆë‹ˆìŠ¤ì¹´í˜", "ëŒ€í˜•ì¹´í˜", "ë¡œìŠ¤í„°ë¦¬"],
    "íšŒì˜": ["íšŒì˜ì‹¤", "ë¯¸íŒ…ë£¸", "ì„¸ë¯¸ë‚˜ì‹¤", "ê³µê°„ëŒ€ì—¬", "ìŠ¤í˜ì´ìŠ¤í´ë¼ìš°ë“œ", "ì‰ì–´ì‡", "ë¹„ì¦ˆë‹ˆìŠ¤ì„¼í„°", "ê³µìœ ì˜¤í”¼ìŠ¤"],
    "ì›Œí¬ìƒµ": ["íŒŒí‹°ë£¸", "ê³µê°„ëŒ€ì—¬", "ì›Œí¬ìƒµì¥ì†Œ", "ìŠ¤íŠœë””ì˜¤", "ì•„ì›Œí”Œë ˆì´ìŠ¤", "ë ŒíƒˆìŠ¤íŠœë””ì˜¤", "ì„¸ë¯¸ë‚˜ì‹¤"],
    "ë¬¸í™”ìƒí™œ": ["ì˜í™”ê´€", "ë¯¸ìˆ ê´€", "ë°•ë¬¼ê´€", "ì „ì‹œíšŒ", "ê³µì—°ì¥", "ì—°ê·¹", "ë®¤ì§€ì»¬", "ì•„íŠ¸ì„¼í„°", "ê°¤ëŸ¬ë¦¬", "ì¶•ì œ"],
    "ì˜í™”ê´€": ["CGV", "ë¡¯ë°ì‹œë„¤ë§ˆ", "ë©”ê°€ë°•ìŠ¤", "ë…ë¦½ì˜í™”ê´€", "ìë™ì°¨ê·¹ì¥", "ê·¹ì¥"],
    "ì „ì‹œíšŒ": ["ë¯¸ìˆ ê´€", "ë°•ë¬¼ê´€", "ê°¤ëŸ¬ë¦¬", "ì „ì‹œ", "íŒì—…ìŠ¤í† ì–´", "ì†Œí’ˆìƒµ"],
    "ì•¡í‹°ë¹„í‹°": ["ë°©íƒˆì¶œ", "ë³´ë“œê²Œì„ì¹´í˜", "ë³¼ë§ì¥", "ì˜¤ë½ì‹¤", "VRì²´í—˜", "ë§Œí™”ì¹´í˜", "ë…¸ë˜ë°©", "ê³µë°©", "ì›ë°ì´í´ë˜ìŠ¤"],
    "ë°©íƒˆì¶œ": ["ë°©íƒˆì¶œ", "ë°©íƒˆì¶œì¹´í˜", "ì´ìŠ¤ì¼€ì´í”„", "ë¹„íŠ¸í¬ë¹„ì•„", "í‚¤ì´ìŠ¤ì¼€ì´í”„"],
    "ì¡°ìš©í•œ": ["ë£¸ì‹ë‹¹", "í”„ë¼ì´ë¹—", "ì¹¸ë§‰ì´", "ë°©ìŒ", "ì¡°ìš©í•œì¹´í˜"],
    "ì£¼ì°¨": ["ì£¼ì°¨ê°€ëŠ¥", "ë°œë ›íŒŒí‚¹", "ë¬´ë£Œì£¼ì°¨"],
    "ê³ ê¸‰ì§„": ["íŒŒì¸ë‹¤ì´ë‹", "í˜¸í…”", "ì˜¤ë§ˆì¹´ì„¸"],
    "ê°€ì„±ë¹„": ["ì €ë ´í•œ", "ì°©í•œê°€ê²©", "ë¬´í•œë¦¬í•„"]
}

# ğŸŒŸ [ì‚¬ìš©ì ìš”ì²­] ì „ì²´ ì§€ì—­ ë¦¬ìŠ¤íŠ¸ (ê·¸ëŒ€ë¡œ ë°˜ì˜)
TARGET_REGIONS = [
    # 1í˜¸ì„ 
    "ì„œìš¸ì—­", "ì‹œì²­", "ì¢…ê°", "ì¢…ë¡œ3ê°€", "ì¢…ë¡œ5ê°€", "ë™ëŒ€ë¬¸", "ë™ë¬˜ì•", "ì‹ ì„¤ë™", "ì œê¸°ë™",
    "ì²­ëŸ‰ë¦¬", "íšŒê¸°", "ìš©ì‚°", "ë…¸ëŸ‰ì§„", "ì˜ë“±í¬", "ì‹ ë„ë¦¼", "êµ¬ë¡œ", "ë¶€ì²œ", "ë¶€í‰", "ì•ˆì–‘", "ìˆ˜ì›",
    # 2í˜¸ì„ 
    "ê°•ë‚¨", "ì—­ì‚¼", "ì‹ ë…¼í˜„", "ì‚¼ì„±", "ì ì‹¤", "ê±´ëŒ€ì…êµ¬", "ì„±ìˆ˜", "ì™•ì‹­ë¦¬", "ì„ì§€ë¡œ3ê°€", "ì„ì§€ë¡œì…êµ¬",
    "í™ëŒ€ì…êµ¬", "í•©ì •", "ì‹ ì´Œ", "ì´ëŒ€", "ë‹¹ì‚°", "êµ¬ë¡œë””ì§€í„¸ë‹¨ì§€", "ì‹ ë¦¼", "ì‚¬ë‹¹", "ì„œì´ˆ", "êµëŒ€",
    # 3í˜¸ì„ 
    "ì—°ì‹ ë‚´", "ë¶ˆê´‘", "ê²½ë³µê¶", "ì•ˆêµ­", "ì¶©ë¬´ë¡œ", "ì•½ìˆ˜", "ì˜¥ìˆ˜", "ì••êµ¬ì •", "ì‹ ì‚¬", "ê³ ì†í„°ë¯¸ë„", "ì–‘ì¬", "ìˆ˜ì„œ",
    # 4í˜¸ì„ 
    "ë…¸ì›", "ì°½ë™", "ì„±ì‹ ì—¬ëŒ€ì…êµ¬", "í˜œí™”", "ëª…ë™", "íšŒí˜„", "ì‚¼ê°ì§€", "ì´ì´Œ", "ì´ìˆ˜", "ê³¼ì²œ", "ë²”ê³„",
    # 5í˜¸ì„ 
    "ê¹€í¬ê³µí•­", "ì—¬ì˜ë„", "ê³µë•", "ê´‘í™”ë¬¸", "ì²­êµ¬", "êµ°ì", "ì²œí˜¸", "ì˜¬ë¦¼í”½ê³µì›",
    # 6í˜¸ì„ 
    "ì´íƒœì›", "í•œê°•ì§„", "ì•ˆì•”", "ê³ ë ¤ëŒ€", "ì„ê³„", "ë§ì›",
    # 7í˜¸ì„ 
    "ê°•ë‚¨êµ¬ì²­", "ë…¼í˜„", "ë‚´ë°©", "ê°€ì‚°ë””ì§€í„¸ë‹¨ì§€", "ì² ì‚°", "ìƒë´‰",
    # 8í˜¸ì„ 
    "ì•”ì‚¬", "ì„ì´Œ", "ê°€ë½ì‹œì¥", "ë¬¸ì •", "ëª¨ë€",
    # 9í˜¸ì„ 
    "ë§ˆê³¡ë‚˜ë£¨", "ì„ ì •ë¦‰", "ë´‰ì€ì‚¬", "ì¢…í•©ìš´ë™ì¥",
    # ê²½ê¸°/ì¸ì²œ
    "íŒêµ", "ë¶„ë‹¹", "ì¼ì‚°", "ì†¡ë„", "ì˜ì •ë¶€"
]

class Preloader:
    def __init__(self):
        self.db = SessionLocal()

    def get_coordinates(self, address: str) -> Tuple[float, float]:
        if not NAVER_MAP_ID: return 0.0, 0.0
        headers = { "X-NCP-APIGW-API-KEY-ID": NAVER_MAP_ID, "X-NCP-APIGW-API-KEY": NAVER_MAP_SECRET }
        try:
            resp = requests.get(GEOCODE_API_URL, headers=headers, params={"query": address})
            if resp.status_code == 200:
                data = resp.json()
                if data.get("addresses"):
                    return float(data["addresses"][0]["y"]), float(data["addresses"][0]["x"])
        except: pass
        return 0.0, 0.0

    def clean_html(self, text):
        return re.sub('<[^<]+?>', '', text)

    def analyze_attributes(self, title, category):
        """ë„¤ì´ë²„ ì¹´í…Œê³ ë¦¬ + ì‚¬ìš©ì ì •ì˜ í‚¤ì›Œë“œ ë§¤ì¹­"""
        tags = set()
        price = 2
        
        # 1. ë„¤ì´ë²„ ì¹´í…Œê³ ë¦¬ íŒŒì‹±
        cats = category.split(">")
        for c in cats:
            c = c.strip()
            if c: tags.add(c)
        
        category_clean = category.replace(">", " ").strip()
        
        # 2. ë©”ì¸ ì¹´í…Œê³ ë¦¬ ê²°ì • (ê¸°ë³¸ ë¡œì§)
        final_cat = "restaurant"
        if any(k in category_clean for k in ["ì¹´í˜", "ì»¤í”¼", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬"]):
            final_cat = "cafe"
        elif any(k in category_clean for k in ["ìˆ ì§‘", "ì£¼ì ", "ì´ìì¹´ì•¼", "ë°”", "í˜¸í”„", "í¬ì°¨"]):
            final_cat = "pub"
            price = 3
        elif any(k in category_clean for k in ["ìŠ¤í„°ë””", "ë…ì„œì‹¤", "ì˜¤í”¼ìŠ¤", "íšŒì˜", "ê³µê°„ëŒ€ì—¬"]):
            final_cat = "workspace"
        
        # 3. ğŸŒŸ [í•µì‹¬] ì‚¬ìš©ì ì •ì˜ í‚¤ì›Œë“œ ì „ì²´ ë§¤ì¹­
        # ì œëª©ì´ë‚˜ ì¹´í…Œê³ ë¦¬ì— í‚¤ì›Œë“œê°€ í¬í•¨ë˜ë©´ í•´ë‹¹ í‚¤ì›Œë“œì™€ ìƒìœ„ ì¹´í…Œê³ ë¦¬(Key)ë¥¼ íƒœê·¸ì— ì¶”ê°€
        for key, keywords in TARGET_KEYWORDS_DICT.items():
            for kw in keywords:
                if kw in title or kw in category_clean:
                    tags.add(kw) # ìƒì„¸ í‚¤ì›Œë“œ (ì˜ˆ: ì†¥ë°¥)
                    tags.add(key) # ìƒìœ„ í‚¤ì›Œë“œ (ì˜ˆ: í•œì‹)
        
        return final_cat, list(tags)

    def save_to_db(self, item, lat, lng):
        title = self.clean_html(item['title'])
        
        # ì¤‘ë³µ ì²´í¬ (ì´ë¦„ + ì¢Œí‘œ 50m ë°˜ê²½)
        existing = self.db.query(models.Place).filter(models.Place.name == title).all()
        for ex in existing:
            if abs(ex.lat - lat) < 0.0005 and abs(ex.lng - lng) < 0.0005:
                # print(f"  â­ï¸ ì¤‘ë³µ ê±´ë„ˆëœ€: {title}")
                return 

        category_raw = item.get('category', '')
        final_cat, tags = self.analyze_attributes(title, category_raw)
        
        address = item.get('roadAddress') or item.get('address')
        
        new_place = models.Place(
            name=title,
            category=final_cat,
            address=address,
            lat=lat,
            lng=lng,
            tags=tags,
            wemeet_rating=round(random.uniform(3.5, 5.0), 1),
            external_link=item.get('link')
        )
        self.db.add(new_place)
        try:
            self.db.commit()
            print(f"  âœ… ì €ì¥: {title} ({final_cat}) - {tags[:3]}...")
        except Exception as e:
            self.db.rollback()
            # print(f"  âŒ ì—ëŸ¬: {e}")

    def run(self):
        # ê²€ìƒ‰í•  ëª¨ë“  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ìƒì„± (ì¤‘ë³µ ì œê±°)
        all_keywords = list(set([k for sublist in TARGET_KEYWORDS_DICT.values() for k in sublist]))
        
        print(f"ğŸš€ [ì „êµ­êµ¬ ë°ì´í„° ìˆ˜ì§‘] ì‹œì‘í•©ë‹ˆë‹¤.")
        print(f"ğŸ“ ìˆ˜ì§‘ ëŒ€ìƒ ì§€ì—­: {len(TARGET_REGIONS)}ê³³")
        print(f"ğŸ”‘ ìˆ˜ì§‘ ëŒ€ìƒ í‚¤ì›Œë“œ: {len(all_keywords)}ê°œ")
        print("--------------------------------------------------")
        
        total_saved = 0
        
        for region in TARGET_REGIONS:
            print(f"\nğŸ“ [{region}] ì§€ì—­ íƒìƒ‰ ì¤‘...")
            
            # ëª¨ë“  í‚¤ì›Œë“œë¥¼ ë‹¤ ëŒë¦½ë‹ˆë‹¤. (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)
            for keyword in all_keywords:
                query = f"{region} {keyword}"
                try:
                    headers = { 
                        "X-Naver-Client-Id": NAVER_SEARCH_ID, 
                        "X-Naver-Client-Secret": NAVER_SEARCH_SECRET 
                    }
                    # ê²€ìƒ‰ ê²°ê³¼ 5ê°œì”© ê°€ì ¸ì˜´
                    resp = requests.get(SEARCH_API_URL, headers=headers, params={"query": query, "display": 5, "sort": "comment"}, timeout=3)
                    
                    if resp.status_code != 200: continue
                    items = resp.json().get('items', [])
                    
                    for item in items:
                        addr = item.get('roadAddress') or item.get('address')
                        if not addr: continue
                        lat, lng = self.get_coordinates(addr)
                        if lat == 0.0: continue
                        
                        self.save_to_db(item, lat, lng)
                        total_saved += 1
                        
                    # ì¿¼í„° ê´€ë¦¬ë¥¼ ìœ„í•´ ì•½ê°„ì˜ ë”œë ˆì´
                    time.sleep(0.05) 
                except Exception as e:
                    print(f"Error processing {query}: {e}")
        
        print(f"\nâœ¨ ì´ {total_saved}ê°œ ì¥ì†Œ ë°ì´í„° ì €ì¥ ì™„ë£Œ!")

if __name__ == "__main__":
    # í…Œì´ë¸”ì´ ì—†ìœ¼ë©´ ìƒì„±
    models.Base.metadata.create_all(bind=engine)
    
    loader = Preloader()
    loader.run()