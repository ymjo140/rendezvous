import sys
import os

# ğŸŒŸ [í•µì‹¬] ì‹œìŠ¤í…œ ê²½ë¡œ ìë™ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

import time
import random
import requests
import re
import numpy as np
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from typing import List, Tuple

# ğŸŒŸ ëª¨ë“ˆ ì„í¬íŠ¸
try:
    import models
    from database import Base, DATABASE_URL
    from constants import NAVER_SEARCH_ID, NAVER_SEARCH_SECRET, NAVER_MAP_ID, NAVER_MAP_SECRET
except ImportError as e:
    print(f"âŒ ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
    sys.exit(1)

# --- ì„¤ì • ---
SEARCH_API_URL = "https://openapi.naver.com/v1/search/local.json"
GEOCODE_API_URL = "https://naveropenapi.apigw.ntruss.com/map-geocode/v2/geocode"

# DB ì—°ê²°
try:
    engine = create_engine(DATABASE_URL)
    SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)
except Exception as e:
    print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜: {e}")
    sys.exit(1)

# ğŸŒŸ [ìˆ˜ì •ë¨] ìŠ¤íŠœë””ì˜¤ ì œê±° (ì‚¬ì§„ê´€ ì¶”ì²œ ë°©ì§€)
TARGET_KEYWORDS_DICT = {
    "í•œì‹": ["í•œì‹", "í•œì •ì‹", "ì†¥ë°¥", "ê°ˆë¹„", "ë¶ˆê³ ê¸°", "ë³´ìŒˆ", "í•œìš°"],
    "ì–‘ì‹": ["ì–‘ì‹", "íŒŒìŠ¤íƒ€", "ìŠ¤í…Œì´í¬", "ë¸ŒëŸ°ì¹˜", "ì´íƒˆë¦¬ì•ˆ", "ë‡¨ë¼", "ë¼ìëƒ", "ì•„ë©”ë¦¬ì¹¸", "ì´íƒœë¦¬"],
    "ì¼ì‹": ["ì¼ì‹", "ìŠ¤ì‹œ", "ë¼ë©˜", "ëˆì¹´ì¸ ", "ëˆê¹ŒìŠ¤", "ìš°ë™", "ê°€ì´ì„¸í‚¤", "ì˜¤ë§ˆì¹´ì„¸", "ì´ìì¹´ì•¼", "ì¼ì‹ì½”ìŠ¤", "í›„í† ë§ˆí‚¤"],
    "ì¤‘ì‹": ["ì¤‘ì‹", "ì¤‘êµ­ìš”ë¦¬", "ì§œì¥ë©´", "ì§¬ë½•", "íƒ•ìˆ˜ìœ¡", "ì¤‘ì‹ë‹¹", "ì½”ìŠ¤ìš”ë¦¬", "ë”¤ì„¬", "í› ê¶ˆ"],
    "ì‹ì‚¬ë¯¸íŒ…": ["ë£¸ì‹ë‹¹", "í•œì •ì‹", "ì¼ì‹ì½”ìŠ¤", "í˜¸í…”ë‹¤ì´ë‹", "ì¡°ìš©í•œì‹ë‹¹", "ì ‘ëŒ€ì¥ì†Œ"],
    "ìˆ ": ["ì´ìì¹´ì•¼", "ì™€ì¸ë°”", "ìœ„ìŠ¤í‚¤ë°”", "í”„ë¼ì´ë¹—ë£¸"],
    "ì»¤í”¼ì±—": ["í˜¸í…”ë¼ìš´ì§€", "ì¡°ìš©í•œì¹´í˜", "ë¹„ì¦ˆë‹ˆìŠ¤ì¹´í˜", "ëŒ€í˜•ì¹´í˜", "ë¡œìŠ¤í„°ë¦¬"],
    "íšŒì˜": ["íšŒì˜ì‹¤", "ë¯¸íŒ…ë£¸", "ì„¸ë¯¸ë‚˜ì‹¤", "ê³µê°„ëŒ€ì—¬", "ìŠ¤í˜ì´ìŠ¤í´ë¼ìš°ë“œ", "ì‰ì–´ì‡", "ë¹„ì¦ˆë‹ˆìŠ¤ì„¼í„°", "ê³µìœ ì˜¤í”¼ìŠ¤"],
    # ğŸš¨ "ìŠ¤íŠœë””ì˜¤", "ë ŒíƒˆìŠ¤íŠœë””ì˜¤" ì œê±°í•¨ (ì‚¬ì§„ê´€ ì´ìŠˆ í•´ê²°)
    "ì›Œí¬ìƒµ": ["íŒŒí‹°ë£¸", "ê³µê°„ëŒ€ì—¬", "ì›Œí¬ìƒµì¥ì†Œ", "ì•„ì›Œí”Œë ˆì´ìŠ¤", "ì„¸ë¯¸ë‚˜ì‹¤"],
    "ë¬¸í™”ìƒí™œ": ["ì˜í™”ê´€", "ë¯¸ìˆ ê´€", "ë°•ë¬¼ê´€", "ì „ì‹œíšŒ", "ê³µì—°ì¥", "ì—°ê·¹", "ë®¤ì§€ì»¬", "ì•„íŠ¸ì„¼í„°", "ê°¤ëŸ¬ë¦¬", "ì¶•ì œ"],
    "ì˜í™”ê´€": ["CGV", "ë¡¯ë°ì‹œë„¤ë§ˆ", "ë©”ê°€ë°•ìŠ¤", "ë…ë¦½ì˜í™”ê´€", "ìë™ì°¨ê·¹ì¥", "ê·¹ì¥"],
    "ì „ì‹œíšŒ": ["ë¯¸ìˆ ê´€", "ë°•ë¬¼ê´€", "ê°¤ëŸ¬ë¦¬", "ì „ì‹œ", "íŒì—…ìŠ¤í† ì–´", "ì†Œí’ˆìƒµ"],
    "ì•¡í‹°ë¹„í‹°": ["ë°©íƒˆì¶œ", "ë³´ë“œê²Œì„ì¹´í˜", "ë³¼ë§ì¥", "ì˜¤ë½ì‹¤", "VRì²´í—˜", "ë§Œí™”ì¹´í˜", "ë…¸ë˜ë°©", "ê³µë°©", "ì›ë°ì´í´ë˜ìŠ¤"],
    "ë°©íƒˆì¶œ": ["ë°©íƒˆì¶œ", "ë°©íƒˆì¶œì¹´í˜", "ì´ìŠ¤ì¼€ì´í”„", "ë¹„íŠ¸í¬ë¹„ì•„", "í‚¤ì´ìŠ¤ì¼€ì´í”„"],
    "ì¡°ìš©í•œ": ["ë£¸ì‹ë‹¹", "í”„ë¼ì´ë¹—", "ì¹¸ë§‰ì´", "ë°©ìŒ", "ì¡°ìš©í•œì¹´í˜"],
    "ì£¼ì°¨": ["ì£¼ì°¨ê°€ëŠ¥", "ë°œë ›íŒŒí‚¹", "ë¬´ë£Œì£¼ì°¨"],
    "ê³ ê¸‰ì§„": ["íŒŒì¸ë‹¤ì´ë‹", "í˜¸í…”", "ì˜¤ë§ˆì¹´ì„¸"],
    "ê°€ì„±ë¹„": ["ì €ë ´í•œ", "ì°©í•œê°€ê²©", "ë¬´í•œë¦¬í•„"]
}

# ğŸŒŸ [ì „ì²´ ì§€ì—­ ë¦¬ìŠ¤íŠ¸]
TARGET_REGIONS = [
    # 1í˜¸ì„ 
    "ì„œìš¸ì—­", "ì‹œì²­", "ì¢…ê°", "ì¢…ë¡œ3ê°€", "ì¢…ë¡œ5ê°€", "ë™ëŒ€ë¬¸", "ë™ë¬˜ì•", "ì‹ ì„¤ë™", "ì œê¸°ë™",
    "ì²­ëŸ‰ë¦¬", "íšŒê¸°", "ìš©ì‚°", "ë…¸ëŸ‰ì§„", "ì˜ë“±í¬", "ì‹ ë„ë¦¼", "êµ¬ë¡œ", "ë¶€ì²œ", "ë¶€í‰", "ì•ˆì–‘", "ìˆ˜ì›",
    # 2í˜¸ì„ 
    "ê°•ë‚¨", "ì—­ì‚¼", "ì‹ ë…¼í˜„", "ì‚¼ì„±", "ì ì‹¤", "ê±´ëŒ€ì…êµ¬", "ì„±ìˆ˜", "ì™•ì‹­ë¦¬", "ì„ì§€ë¡œ3ê°€", "ì„ì§€ë¡œì…êµ¬",
    "í™ëŒ€ì…êµ¬", "í•©ì •", "ì‹ ì´Œ", "ì´ëŒ€", "ë‹¹ì‚°", "êµ¬ë¡œë””ì§€í„¸ë‹¨ì§€", "ì‹ ë¦¼", "ì‚¬ë‹¹", "ì„œì´ˆ", "êµëŒ€",
    # 3í˜¸ì„ 
    "ì—°ì‹ ë‚´", "ë¶ˆê´‘", "ê²½ë³µê¶", "ì•ˆêµ­", "ì¶©ë¬´ë¡œ", "ì•½ìˆ˜", "ì˜¥ìˆ˜", "ì••êµ¬ì •", "ì‹ ì‚¬", "ê³ ì†í„°ë¯¸ë„", "ì–‘ì¬", "ìˆ˜ì„œ",
    # 4í˜¸ì„ 
    "ë…¸ì›", "ì°½ë™", "ì„±ì‹ ì—¬ëŒ€ì…êµ¬", "í˜œí™”", "ëª…ë™", "íšŒí˜„", "ì‚¼ê°ì§€", "ì´ì´Œ", "ì´ìˆ˜", "ê³¼ì²œ", "ë²”ê³„",
    # 5í˜¸ì„ 
    "ê¹€í¬ê³µí•­", "ì—¬ì˜ë„", "ê³µë•", "ê´‘í™”ë¬¸", "ì²­êµ¬", "êµ°ì", "ì²œí˜¸", "ì˜¬ë¦¼í”½ê³µì›",
    # 6í˜¸ì„ 
    "ì´íƒœì›", "í•œê°•ì§„", "ì•ˆì•”", "ê³ ë ¤ëŒ€", "ì„ê³„", "ë§ì›",
    # 7í˜¸ì„ 
    "ê°•ë‚¨êµ¬ì²­", "ë…¼í˜„", "ë‚´ë°©", "ê°€ì‚°ë””ì§€í„¸ë‹¨ì§€", "ì² ì‚°", "ìƒë´‰",
    # 8í˜¸ì„ 
    "ì•”ì‚¬", "ì„ì´Œ", "ê°€ë½ì‹œì¥", "ë¬¸ì •", "ëª¨ë€",
    # 9í˜¸ì„ 
    "ë§ˆê³¡ë‚˜ë£¨", "ì„ ì •ë¦‰", "ë´‰ì€ì‚¬", "ì¢…í•©ìš´ë™ì¥",
    # ê²½ê¸°/ì¸ì²œ
    "íŒêµ", "ë¶„ë‹¹", "ì¼ì‚°", "ì†¡ë„", "ì˜ì •ë¶€"
]

class Preloader:
    def __init__(self):
        self.db = SessionLocal()

    def get_coordinates(self, address: str) -> Tuple[float, float]:
        if not NAVER_MAP_ID: 
            print("  âš ï¸ ë„¤ì´ë²„ ì§€ë„ API í‚¤(NAVER_MAP_ID)ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return 0.0, 0.0
            
        headers = { "X-NCP-APIGW-API-KEY-ID": NAVER_MAP_ID, "X-NCP-APIGW-API-KEY": NAVER_MAP_SECRET }
        try:
            resp = requests.get(GEOCODE_API_URL, headers=headers, params={"query": address})
            if resp.status_code != 200:
                print(f"  âš ï¸ Geocoding ì‹¤íŒ¨ ({resp.status_code}): {address}")
                return 0.0, 0.0
            
            data = resp.json()
            if data.get("addresses"):
                return float(data["addresses"][0]["y"]), float(data["addresses"][0]["x"])
            else:
                # print(f"  âš ï¸ ì¢Œí‘œ ì—†ìŒ: {address}")
                return 0.0, 0.0
        except Exception as e:
            print(f"  âš ï¸ ì¢Œí‘œ API ì—ëŸ¬: {e}")
            return 0.0, 0.0

    def clean_html(self, text):
        return re.sub('<[^<]+?>', '', text)

    def analyze_attributes(self, title, category):
        tags = set()
        price = 2
        
        cats = category.split(">")
        for c in cats:
            c = c.strip()
            if c: tags.add(c)
        
        category_clean = category.replace(">", " ").strip()
        title_clean = title.replace(" ", "")

        # ğŸŒŸ [í•„í„°ë§] ì‚¬ì§„ê´€/ì´¬ì˜ì†Œ ì ˆëŒ€ ì œì™¸
        if any(bad in title_clean or bad in category_clean for bad in ["ì‚¬ì§„ê´€", "ìŠ¤íŠœë””ì˜¤", "ì´¬ì˜", "í¬í† ", "photo", "studio"]):
            # ë‹¨, "ì¿ í‚¹ìŠ¤íŠœë””ì˜¤" ë“±ì€ ì‚´ë ¤ì•¼ í•  ìˆ˜ë„ ìˆì§€ë§Œ, ì¼ë‹¨ ì›Œí¬ìƒµ ëª©ì ì˜ ì•ˆì „ì„ ìœ„í•´ ìŠ¤íŠœë””ì˜¤ëŠ” ì—„ê²©íˆ ë°°ì œí•˜ê±°ë‚˜
            # "ê³µê°„ëŒ€ì—¬"ê°€ ëª…ì‹œëœ ê²½ìš°ë§Œ í—ˆìš©í•´ì•¼ í•¨. ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ 'junk' ì²˜ë¦¬.
            if "ê³µê°„ëŒ€ì—¬" not in category_clean and "íŒŒí‹°ë£¸" not in category_clean:
                return "junk", []

        # ë©”ì¸ ì¹´í…Œê³ ë¦¬ ê²°ì •
        final_cat = "restaurant"
        if any(k in category_clean for k in ["ì¹´í˜", "ì»¤í”¼", "ë””ì €íŠ¸", "ë² ì´ì»¤ë¦¬"]): final_cat = "cafe"
        elif any(k in category_clean for k in ["ìˆ ì§‘", "ì£¼ì ", "ì´ìì¹´ì•¼", "ë°”", "í˜¸í”„", "í¬ì°¨"]): final_cat = "pub"; price = 3
        elif any(k in category_clean for k in ["ìŠ¤í„°ë””", "ë…ì„œì‹¤", "ì˜¤í”¼ìŠ¤", "íšŒì˜", "ê³µê°„ëŒ€ì—¬", "íŒŒí‹°ë£¸"]): final_cat = "workspace"
        
        # ìƒì„¸ í‚¤ì›Œë“œ ë§¤ì¹­
        for key, keywords in TARGET_KEYWORDS_DICT.items():
            for kw in keywords:
                if kw in title or kw in category_clean:
                    tags.add(kw)
                    tags.add(key)
        
        return final_cat, list(tags)

    def save_to_db(self, item, lat, lng):
        title = self.clean_html(item['title'])
        category_raw = item.get('category', '')
        
        # ì†ì„± ë¶„ì„ ë° í•„í„°ë§
        final_cat, tags = self.analyze_attributes(title, category_raw)
        
        # ğŸŒŸ 'junk' ì¹´í…Œê³ ë¦¬(ì‚¬ì§„ê´€ ë“±)ëŠ” ì €ì¥í•˜ì§€ ì•ŠìŒ
        if final_cat == "junk": 
            # print(f"  ğŸ—‘ï¸ ì œì™¸ë¨(ì‚¬ì§„ê´€ ë“±): {title}")
            return

        # ì¤‘ë³µ ì²´í¬
        existing = self.db.query(models.Place).filter(models.Place.name == title).all()
        for ex in existing:
            if abs(ex.lat - lat) < 0.0005 and abs(ex.lng - lng) < 0.0005:
                return 

        address = item.get('roadAddress') or item.get('address') or ""
        
        new_place = models.Place(
            name=title,
            category=final_cat,
            address=address,
            lat=lat,
            lng=lng,
            tags=tags,
            wemeet_rating=round(random.uniform(3.5, 5.0), 1),
            external_link=item.get('link')
        )
        self.db.add(new_place)
        try:
            self.db.commit()
            print(f"  âœ… ì €ì¥: {title} ({final_cat})")
        except Exception as e:
            self.db.rollback()

    def run(self):
        # ì „ì²´ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        all_keywords = list(set([k for sublist in TARGET_KEYWORDS_DICT.values() for k in sublist]))
        
        print(f"ğŸš€ [ì „êµ­êµ¬ ë°ì´í„° ìˆ˜ì§‘] ì‹œì‘í•©ë‹ˆë‹¤.")
        print(f"ğŸ“ ìˆ˜ì§‘ ëŒ€ìƒ ì§€ì—­: {len(TARGET_REGIONS)}ê³³")
        print(f"ğŸ”‘ ìˆ˜ì§‘ ëŒ€ìƒ í‚¤ì›Œë“œ: {len(all_keywords)}ê°œ (ì‚¬ìš©ìê°€ ì§€ì •í•œ ì „ì²´ ë¦¬ìŠ¤íŠ¸)")
        print("--------------------------------------------------")
        
        if not NAVER_SEARCH_ID:
            print("âŒ ë„¤ì´ë²„ ê²€ìƒ‰ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            return

        total_saved = 0
        
        for region in TARGET_REGIONS:
            print(f"\nğŸ“ [{region}] íƒìƒ‰ ì¤‘...")
            
            # ğŸŒŸ ì‚¬ìš©ìê°€ ìš”ì²­í•œ 'ì „ì²´ í‚¤ì›Œë“œ'ë¡œ ë£¨í”„ ì‹¤í–‰
            for keyword in all_keywords:
                query = f"{region} {keyword}"
                try:
                    headers = { 
                        "X-Naver-Client-Id": NAVER_SEARCH_ID, 
                        "X-Naver-Client-Secret": NAVER_SEARCH_SECRET 
                    }
                    # ì •í™•ë„ìˆœ(comment) ëŒ€ì‹  random(ìœ ì‚¬ë„) or vote(ì¸ê¸°ë„) ì‚¬ìš© ê°€ëŠ¥
                    # ì—¬ê¸°ì„œëŠ” ë‹¤ì–‘í•œ ë°ì´í„°ë¥¼ ìœ„í•´ 'random' ì¶”ì²œ, í˜¹ì€ ì •í™•í•œ ë§¤ì¹­ì„ ìœ„í•´ 'sim'
                    resp = requests.get(SEARCH_API_URL, headers=headers, params={"query": query, "display": 5, "sort": "comment"}, timeout=3)
                    
                    if resp.status_code != 200: 
                        print(f"âŒ ê²€ìƒ‰ API ì‹¤íŒ¨: {resp.status_code}")
                        continue
                        
                    items = resp.json().get('items', [])
                    if not items: continue

                    for item in items:
                        addr = item.get('roadAddress') or item.get('address')
                        if not addr: continue
                        
                        # ì¢Œí‘œ ë³€í™˜ (ì‹¤íŒ¨ ì‹œ ë¡œê·¸ ì¶œë ¥ë¨)
                        lat, lng = self.get_coordinates(addr)
                        
                        # ì¢Œí‘œê°€ 0.0ì´ë©´ ì €ì¥ ë¶ˆê°€ (ì§€ë„ì— ëª» ë„ì›€)
                        if lat == 0.0: continue
                        
                        self.save_to_db(item, lat, lng)
                        total_saved += 1
                    
                    # API í˜¸ì¶œ ì œí•œ ë°©ì§€ (0.05ì´ˆ)
                    time.sleep(0.05) 
                except Exception as e:
                    print(f"Error processing {query}: {e}")
        
        print(f"\nâœ¨ ì´ {total_saved}ê°œ ì¥ì†Œ ë°ì´í„° ì €ì¥ ì™„ë£Œ!")

if __name__ == "__main__":
    # í…Œì´ë¸” ìƒì„± (í˜¹ì‹œ ì—†ìœ¼ë©´)
    models.Base.metadata.create_all(bind=engine)
    
    loader = Preloader()
    loader.run()